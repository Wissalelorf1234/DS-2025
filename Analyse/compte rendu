# COMPTE RENDU : D√âTECTION DE FRAUDE PAR CARTE BANCAIRE

## TABLE DES MATI√àRES
1. Introduction
2. Description du Dataset
3. Contexte et Enjeux de la Fraude
4. Analyse Exploratoire des Donn√©es
5. Visualisations Graphiques
6. Analyse de D√©s√©quilibre des Classes
7. Mod√®les de Classification
8. Conclusion

---

## 1. INTRODUCTION

Le **Credit Card Fraud Detection Dataset** est un jeu de donn√©es crucial pour la s√©curit√© financi√®re, permettant de d√©velopper des syst√®mes de d√©tection automatique des transactions frauduleuses par carte bancaire.

**Probl√©matique** : Comment identifier avec pr√©cision les transactions frauduleuses parmi des millions de transactions l√©gitimes, tout en minimisant les faux positifs qui perturbent l'exp√©rience client ?

**URL** : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

---

## 2. DESCRIPTION DU DATASET

### Caract√©ristiques g√©n√©rales
- **Nombre d'observations** : 284,807 transactions
- **P√©riode couverte** : Septembre 2013 (2 jours)
- **Nombre de variables** : 31
- **Variable cible** : Class (0 = l√©gitime, 1 = frauduleuse)

### Types de variables

**Variables transform√©es (PCA)** : V1, V2, V3, ..., V28
- 28 composantes principales issues d'une transformation PCA
- Variables anonymis√©es pour prot√©ger la confidentialit√© des donn√©es
- Repr√©sentent des caract√©ristiques cach√©es des transactions

**Variables non transform√©es** :
- **Time** : Secondes √©coul√©es entre chaque transaction et la premi√®re du dataset
- **Amount** : Montant de la transaction (en euros)
- **Class** : Variable cible (0 = transaction normale, 1 = fraude)

### D√©s√©quilibre des classes
- **Transactions l√©gitimes** : 284,315 (99.827%)
- **Transactions frauduleuses** : 492 (0.173%)
- **Ratio** : environ 1 fraude pour 577 transactions l√©gitimes

---

## 3. CONTEXTE ET ENJEUX DE LA FRAUDE

### Origine des donn√©es
Les donn√©es proviennent de transactions r√©elles effectu√©es par des porteurs de cartes bancaires europ√©ens. Pour des raisons de confidentialit√©, les variables originales ont √©t√© transform√©es via PCA (Principal Component Analysis).

### Impact √©conomique
- **Pertes mondiales estim√©es** : Plus de 30 milliards de dollars par an
- **Co√ªt moyen d'une fraude** : Variable selon le montant et le type de transaction
- **Co√ªt des faux positifs** : Frustration client, perte de confiance, blocages injustifi√©s

### Types de fraudes courants
1. **Fraude par carte perdue/vol√©e**
2. **Fraude sans pr√©sence de carte** (e-commerce)
3. **Skimming** (copie de carte)
4. **Fraude par ing√©nierie sociale**
5. **Fraude d'identit√©**

### D√©fis techniques
- ‚ö†Ô∏è **D√©s√©quilibre extr√™me** : Moins de 0.2% de fraudes
- ‚è±Ô∏è **Temps r√©el** : D√©cision en millisecondes
- üí∞ **Co√ªt asym√©trique** : Manquer une fraude co√ªte plus cher qu'un faux positif
- üîÑ **√âvolution constante** : Les fraudeurs adaptent leurs techniques

---

## 4. ANALYSE EXPLORATOIRE DES DONN√âES

### Statistiques descriptives de Amount

| Statistique | Valeur |
|-------------|--------|
| Moyenne | ‚Ç¨88.35 |
| M√©diane | ‚Ç¨22.00 |
| √âcart-type | ‚Ç¨250.12 |
| Minimum | ‚Ç¨0.00 |
| Maximum | ‚Ç¨25,691.16 |

### Distribution des montants

**Transactions l√©gitimes** :
- M√©diane : ‚Ç¨22.00
- Montant moyen : ‚Ç¨88.29

**Transactions frauduleuses** :
- M√©diane : ‚Ç¨9.25
- Montant moyen : ‚Ç¨122.21

**Observation cl√©** : Les transactions frauduleuses ont tendance √† avoir des montants plus √©lev√©s en moyenne, mais une m√©diane plus faible, sugg√©rant deux patterns distincts.

### Analyse temporelle
- **Dur√©e totale** : 172,792 secondes (~48 heures)
- **Distribution** : Les fraudes ne montrent pas de pattern temporel √©vident
- **Pics d'activit√©** : Variations normales du volume de transactions

---

## 5. VISUALISATIONS GRAPHIQUES

### Code Python pour les graphiques

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Chargement des donn√©es
df = pd.read_csv('creditcard.csv')

# Configuration style
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (14, 8)

# ========================================
# 1. DISTRIBUTION DES CLASSES
# ========================================

plt.figure(figsize=(10, 6))
class_counts = df['Class'].value_counts()
colors = ['#2ecc71', '#e74c3c']
plt.bar(['L√©gitime', 'Fraude'], class_counts.values, color=colors, edgecolor='black', linewidth=1.5)
plt.title('Distribution des Classes', fontsize=16, fontweight='bold')
plt.ylabel('Nombre de Transactions', fontsize=12)
plt.yscale('log')  # √âchelle logarithmique pour mieux voir la diff√©rence
for i, v in enumerate(class_counts.values):
    plt.text(i, v, f'{v:,}\n({v/len(df)*100:.3f}%)', ha='center', va='bottom', fontweight='bold')
plt.tight_layout()
plt.show()

# ========================================
# 2. DISTRIBUTION DES MONTANTS
# ========================================

fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Toutes les transactions
axes[0].hist(df['Amount'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)
axes[0].set_xlabel('Montant (‚Ç¨)', fontsize=12)
axes[0].set_ylabel('Fr√©quence', fontsize=12)
axes[0].set_title('Distribution des Montants - Toutes Transactions', fontsize=14, fontweight='bold')
axes[0].set_xlim([0, 1000])  # Limite pour meilleure visualisation

# Comparaison L√©gitime vs Fraude
legitimate = df[df['Class'] == 0]['Amount']
fraud = df[df['Class'] == 1]['Amount']

axes[1].hist(legitimate, bins=50, alpha=0.6, label='L√©gitime', color='green', edgecolor='black')
axes[1].hist(fraud, bins=50, alpha=0.6, label='Fraude', color='red', edgecolor='black')
axes[1].set_xlabel('Montant (‚Ç¨)', fontsize=12)
axes[1].set_ylabel('Fr√©quence', fontsize=12)
axes[1].set_title('Comparaison des Montants : L√©gitime vs Fraude', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=12)
axes[1].set_xlim([0, 500])

plt.tight_layout()
plt.show()

# ========================================
# 3. BOXPLOT DES MONTANTS PAR CLASSE
# ========================================

plt.figure(figsize=(10, 6))
sns.boxplot(x='Class', y='Amount', data=df, palette=['#2ecc71', '#e74c3c'])
plt.xticks([0, 1], ['L√©gitime (0)', 'Fraude (1)'])
plt.xlabel('Type de Transaction', fontsize=12)
plt.ylabel('Montant (‚Ç¨)', fontsize=12)
plt.title('Distribution des Montants par Classe', fontsize=14, fontweight='bold')
plt.ylim([0, 300])  # Limite pour meilleure lisibilit√©
plt.tight_layout()
plt.show()

# ========================================
# 4. DISTRIBUTION TEMPORELLE
# ========================================

fig, axes = plt.subplots(2, 1, figsize=(14, 10))

# Toutes les transactions
axes[0].plot(df['Time'], df['Amount'], 'o', alpha=0.3, markersize=1, color='steelblue')
axes[0].set_xlabel('Temps (secondes)', fontsize=12)
axes[0].set_ylabel('Montant (‚Ç¨)', fontsize=12)
axes[0].set_title('Distribution Temporelle des Transactions', fontsize=14, fontweight='bold')
axes[0].set_ylim([0, 2000])

# Focus sur les fraudes
fraud_df = df[df['Class'] == 1]
axes[1].scatter(fraud_df['Time'], fraud_df['Amount'], color='red', alpha=0.7, s=50, edgecolor='black')
axes[1].set_xlabel('Temps (secondes)', fontsize=12)
axes[1].set_ylabel('Montant (‚Ç¨)', fontsize=12)
axes[1].set_title('Distribution Temporelle des Fraudes', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ========================================
# 5. DISTRIBUTION DES VARIABLES V1-V28
# ========================================

# S√©lection de quelques variables PCA importantes
important_features = ['V1', 'V2', 'V3', 'V4', 'V9', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18']

fig, axes = plt.subplots(3, 4, figsize=(18, 12))
axes = axes.ravel()

for idx, feature in enumerate(important_features):
    axes[idx].hist(df[df['Class'] == 0][feature], bins=50, alpha=0.6, label='L√©gitime', color='green', density=True)
    axes[idx].hist(df[df['Class'] == 1][feature], bins=50, alpha=0.6, label='Fraude', color='red', density=True)
    axes[idx].set_title(f'Distribution de {feature}', fontweight='bold')
    axes[idx].legend()
    axes[idx].set_ylabel('Densit√©')

plt.suptitle('Distribution des Composantes PCA', fontsize=16, fontweight='bold', y=1.00)
plt.tight_layout()
plt.show()

# ========================================
# 6. STATISTIQUES DESCRIPTIVES
# ========================================

print("=" * 80)
print("STATISTIQUES DESCRIPTIVES")
print("=" * 80)

print("\nüìä INFORMATIONS G√âN√âRALES :")
print(f"Nombre total de transactions : {len(df):,}")
print(f"Transactions l√©gitimes : {len(df[df['Class']==0]):,} ({len(df[df['Class']==0])/len(df)*100:.3f}%)")
print(f"Transactions frauduleuses : {len(df[df['Class']==1]):,} ({len(df[df['Class']==1])/len(df)*100:.3f}%)")

print("\nüí∞ MONTANTS DES TRANSACTIONS :")
print(f"\nToutes transactions :")
print(f"  - Moyenne : ‚Ç¨{df['Amount'].mean():.2f}")
print(f"  - M√©diane : ‚Ç¨{df['Amount'].median():.2f}")
print(f"  - √âcart-type : ‚Ç¨{df['Amount'].std():.2f}")
print(f"  - Min : ‚Ç¨{df['Amount'].min():.2f}")
print(f"  - Max : ‚Ç¨{df['Amount'].max():.2f}")

legitimate_amount = df[df['Class'] == 0]['Amount']
fraud_amount = df[df['Class'] == 1]['Amount']

print(f"\nTransactions l√©gitimes :")
print(f"  - Moyenne : ‚Ç¨{legitimate_amount.mean():.2f}")
print(f"  - M√©diane : ‚Ç¨{legitimate_amount.median():.2f}")

print(f"\nTransactions frauduleuses :")
print(f"  - Moyenne : ‚Ç¨{fraud_amount.mean():.2f}")
print(f"  - M√©diane : ‚Ç¨{fraud_amount.median():.2f}")

print("\n‚è±Ô∏è INFORMATIONS TEMPORELLES :")
print(f"Dur√©e totale : {df['Time'].max():,} secondes (~{df['Time'].max()/3600:.1f} heures)")
```

---

## 6. ANALYSE DE D√âS√âQUILIBRE DES CLASSES

### Impact du d√©s√©quilibre

Le d√©s√©quilibre extr√™me (99.827% vs 0.173%) pose plusieurs d√©fis :

1. **Biais du mod√®le** : Tendance √† pr√©dire toujours "l√©gitime"
2. **M√©triques trompeuses** : 99.83% d'accuracy en pr√©disant toujours 0
3. **Apprentissage insuffisant** : Peu d'exemples de fraudes pour l'entra√Ænement

### Techniques de gestion du d√©s√©quilibre

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from collections import Counter

# Chargement des donn√©es
df = pd.read_csv('creditcard.csv')

X = df.drop('Class', axis=1)
y = df['Class']

# Split des donn√©es
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("=" * 80)
print("TECHNIQUES DE GESTION DU D√âS√âQUILIBRE")
print("=" * 80)

print(f"\nüìä Distribution originale :")
print(f"Classe 0 (L√©gitime) : {sum(y_train == 0):,}")
print(f"Classe 1 (Fraude) : {sum(y_train == 1):,}")
print(f"Ratio : {sum(y_train == 0) / sum(y_train == 1):.1f}:1")

# ========================================
# TECHNIQUE 1 : SMOTE (Over-sampling)
# ========================================

print("\n" + "=" * 80)
print("1Ô∏è‚É£ SMOTE (Synthetic Minority Over-sampling)")
print("=" * 80)

smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print(f"Apr√®s SMOTE :")
print(f"Classe 0 : {sum(y_train_smote == 0):,}")
print(f"Classe 1 : {sum(y_train_smote == 1):,}")
print(f"Ratio : 1:1 (√©quilibr√©)")

# ========================================
# TECHNIQUE 2 : Under-sampling
# ========================================

print("\n" + "=" * 80)
print("2Ô∏è‚É£ Random Under-sampling")
print("=" * 80)

rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

print(f"Apr√®s Under-sampling :")
print(f"Classe 0 : {sum(y_train_rus == 0):,}")
print(f"Classe 1 : {sum(y_train_rus == 1):,}")
print(f"Ratio : 1:1 (√©quilibr√©)")

# ========================================
# VISUALISATION
# ========================================

import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Original
axes[0].bar(['L√©gitime', 'Fraude'], [sum(y_train == 0), sum(y_train == 1)], 
            color=['green', 'red'], edgecolor='black', linewidth=1.5)
axes[0].set_title('Distribution Originale', fontsize=14, fontweight='bold')
axes[0].set_ylabel('Nombre de samples')
axes[0].set_yscale('log')

# SMOTE
axes[1].bar(['L√©gitime', 'Fraude'], [sum(y_train_smote == 0), sum(y_train_smote == 1)], 
            color=['green', 'red'], edgecolor='black', linewidth=1.5)
axes[1].set_title('Apr√®s SMOTE', fontsize=14, fontweight='bold')
axes[1].set_ylabel('Nombre de samples')

# Under-sampling
axes[2].bar(['L√©gitime', 'Fraude'], [sum(y_train_rus == 0), sum(y_train_rus == 1)], 
            color=['green', 'red'], edgecolor='black', linewidth=1.5)
axes[2].set_title('Apr√®s Under-sampling', fontsize=14, fontweight='bold')
axes[2].set_ylabel('Nombre de samples')

plt.tight_layout()
plt.show()
```

---

## 7. MOD√àLES DE CLASSIFICATION

### Code Python pour les mod√®les

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report,
    roc_curve, precision_recall_curve
)
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

# ========================================
# 1. PR√âPARATION DES DONN√âES
# ========================================

df = pd.read_csv('creditcard.csv')

X = df.drop('Class', axis=1)
y = df['Class']

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Normalisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Application de SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

print("=" * 80)
print("PR√âPARATION DES DONN√âES")
print("=" * 80)
print(f"‚úì Taille du dataset : {len(df):,} transactions")
print(f"‚úì Train set : {len(X_train):,} samples")
print(f"‚úì Test set : {len(X_test):,} samples")
print(f"‚úì Train set apr√®s SMOTE : {len(X_train_balanced):,} samples")
print(f"‚úì Distribution apr√®s SMOTE : {Counter(y_train_balanced)}")

# ========================================
# 2. D√âFINITION DES MOD√àLES
# ========================================

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, eval_metric='logloss')
}

# ========================================
# 3. ENTRA√éNEMENT ET √âVALUATION
# ========================================

results = []
predictions = {}
probabilities = {}

print("\n" + "=" * 80)
print("ENTRA√éNEMENT ET √âVALUATION DES MOD√àLES")
print("=" * 80)

for name, model in models.items():
    print(f"\nüîÑ Entra√Ænement : {name}...")
    
    # Entra√Ænement
    model.fit(X_train_balanced, y_train_balanced)
    
    # Pr√©dictions
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
    
    predictions[name] = y_pred
    probabilities[name] = y_pred_proba
    
    # Calcul des m√©triques
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 0
    
    results.append({
        'Mod√®le': name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'ROC-AUC': roc_auc
    })
    
    print(f"  ‚úì Accuracy : {accuracy:.4f}")
    print(f"  ‚úì Precision : {precision:.4f}")
    print(f"  ‚úì Recall : {recall:.4f}")
    print(f"  ‚úì F1-Score : {f1:.4f}")
    print(f"  ‚úì ROC-AUC : {roc_auc:.4f}")

# ========================================
# 4. TABLEAU R√âCAPITULATIF
# ========================================

results_df = pd.DataFrame(results).sort_values('F1-Score', ascending=False)

print("\n" + "=" * 80)
print("TABLEAU R√âCAPITULATIF DES PERFORMANCES")
print("=" * 80)
print(results_df.to_string(index=False))

# ========================================
# 5. VISUALISATIONS
# ========================================

# Graphique de comparaison des m√©triques
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']

for idx, metric in enumerate(metrics):
    ax = axes[idx // 2, idx % 2]
    sorted_df = results_df.sort_values(metric, ascending=True)
    ax.barh(sorted_df['Mod√®le'], sorted_df[metric], color=colors[idx], edgecolor='black', linewidth=1.5)
    ax.set_xlabel(metric, fontsize=12, fontweight='bold')
    ax.set_xlim([0, 1])
    ax.set_title(f'Comparaison : {metric}', fontsize=14, fontweight='bold')
    
    # Ajout des valeurs sur les barres
    for i, v in enumerate(sorted_df[metric]):
        ax.text(v + 0.01, i, f'{v:.3f}', va='center', fontweight='bold')

plt.tight_layout()
plt.show()

# ========================================
# 6. MATRICE DE CONFUSION (MEILLEUR MOD√àLE)
# ========================================

best_model_name = results_df.iloc[0]['Mod√®le']
best_predictions = predictions[best_model_name]

print(f"\nüèÜ Meilleur mod√®le : {best_model_name}")

cm = confusion_matrix(y_test, best_predictions)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,
            xticklabels=['L√©gitime', 'Fraude'],
            yticklabels=['L√©gitime', 'Fraude'],
            annot_kws={'size': 16, 'weight': 'bold'})
plt.title(f'Matrice de Confusion - {best_model_name}', fontsize=14, fontweight='bold')
plt.ylabel('Valeur R√©elle', fontsize=12)
plt.xlabel('Valeur Pr√©dite', fontsize=12)
plt.tight_layout()
plt.show()

# Affichage d√©taill√© de la matrice
TN, FP, FN, TP = cm.ravel()
print(f"\nüìä D√©tails de la matrice de confusion :")
print(f"  ‚Ä¢ True Negatives (TN)  : {TN:,} (vraies l√©gitimes)")
print(f"  ‚Ä¢ False Positives (FP) : {FP:,} (fausses alertes)")
print(f"  ‚Ä¢ False Negatives (FN) : {FN:,} (fraudes manqu√©es) ‚ö†Ô∏è")
print(f"  ‚Ä¢ True Positives (TP)  : {TP:,} (fraudes d√©tect√©es) ‚úì")

# ========================================
# 7. COURBE ROC
# ========================================

plt.figure(figsize=(10, 8))

for name, proba in probabilities.items():
    if proba is not None:
        fpr, tpr, _ = roc_curve(y_test, proba)
        auc = roc_auc_score(y_test, proba)
        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)

plt.plot([0, 1], [0, 1], 'k--', label='Hasard (AUC = 0.500)', linewidth=2)
plt.xlabel('Taux de Faux Positifs', fontsize=12)
plt.ylabel('Taux de Vrais Positifs', fontsize=12)
plt.title('Courbes ROC - Comparaison des Mod√®les', fontsize=14, fontweight='bold')
plt.legend(loc='lower right', fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# ========================================
# 8. COURBE PRECISION-RECALL
# ========================================

plt.figure(figsize=(10, 8))

for name, proba in probabilities.items():
    if proba is not None:
        precision_vals, recall_vals, _ = precision_recall_curve(y_test, proba)
        plt.plot(recall_vals, precision_vals, label=name, linewidth=2)

plt.xlabel('Recall', fontsize=12)
plt.ylabel('Precision', fontsize=12)
plt.title('Courbes Precision-Recall', fontsize=14, fontweight='bold')
plt.legend(loc='lower left', fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# ========================================
# 9. RAPPORT DE CLASSIFICATION
# ========================================

print("\n" + "=" * 80)
print(f"RAPPORT DE CLASSIFICATION D√âTAILL√â - {best_model_name}")
print("=" * 80)
print(classification_report(y_test, best_predictions, target_names=['L√©gitime', 'Fraude']))

print("\n‚úì Analyse de classification termin√©e")
```

### R√©sultats attendus

Les mod√®les bas√©s sur les ensembles obtiennent g√©n√©ralement les meilleures performances :

| M√©trique | Random Forest | XGBoost | Gradient Boosting |
|----------|---------------|---------|-------------------|
| **Accuracy** | 0.9995 | 0.9996 | 0.9994 |
| **Precision** | 0.95 - 0.98 | 0.96 - 0.99 | 0.94 - 0.97 |
| **Recall** | 0.85 - 0.92 | 0.88 - 0.94 | 0.83 - 0.90 |
| **F1-Score** | 0.90 - 0.95 | 0.92 - 0.96 | 0.88 - 0.93 |
| **ROC-AUC** | 0.97 - 0.99 | 0.98 - 0.99 | 0.96 - 0.98 |

---

## 8. CONCLUSION

### Points cl√©s

‚úÖ **Dataset r√©aliste** : 284,807 transactions authentiques avec anonymisation PCA  
‚úÖ **D√©fi majeur** : D√©s√©quilibre extr√™me (0.173% de fraudes)  
‚úÖ **Techniques essentielles** : SMOTE, ajustement des seuils, m√©triques adapt√©es  
‚úÖ **Mod√®les performants** : XGBoost et Random Forest excellent avec ROC-AUC > 0.98  
‚úÖ **M√©trique prioritaire** : Le Recall est crucial (minimiser les fraudes manqu√©es)

### Recommandations

1. **Feature Engineering**
   - Cr√©er des agr√©gations temporelles (transactions par heure/jour)
   - Calculer des statistiques par utilisateur (fr√©quence, montant moyen)
   - Analyser les patterns de comportement

2. **Optimisation des seuils**
   - Ajuster le seuil de d√©cision selon le co√ªt m√©tier
   - Privil√©gier le Recall pour minimiser les fraudes manqu√©es
   - √âquilibrer avec les faux positifs pour l'exp√©rience client

3. **Validation robuste**
   - Validation crois√©e stratifi√©e
   - √âvaluation sur donn√©es temporellement s√©par√©es
   - Tests sur nouveaux types de fraudes

4. **D√©ploiement en production**
   - Scoring en temps r√©el (< 100ms)
   - Syst√®me de r√®gles m√©tier compl√©mentaire
   - Monitoring continu des performances
   - R√©entra√Ænement r√©gulier du mod√®le

5. **Gestion des co√ªts**
   - Co√ªt d'une fraude manqu√©e : √©lev√© (perte du montant + frais)
   - Co√ªt d'un faux positif : mod√©r√© (friction client)
   - Optimiser selon la matrice de co√ªts m√©tier

### Applications pratiques

- üè¶ **Syst√®mes bancaires** : D√©tection en temps r√©el des transactions suspectes
- üí≥ **√âmetteurs de cartes** : Scoring de risque pour chaque transaction
- üõ°Ô∏è **Pr√©vention** : Identification des patterns de fraude √©mergents
- üìä **Analyse forensique** : Investigation post-fraude
- ü§ñ **Automatisation** : R√©duction de la r√©vision manuelle

### Lim



le code 
"""
=================================================================================
COMPTE RENDU : D√âTECTION DE FRAUDE PAR CARTE BANCAIRE
=================================================================================
Dataset: Credit Card Fraud Detection
Source: Kaggle - https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
Auteur: Analyse compl√®te
Date: Novembre 2025
=================================================================================
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from collections import Counter

# Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier

# M√©triques
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report,
    roc_curve, precision_recall_curve
)

# Gestion du d√©s√©quilibre
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

import warnings
warnings.filterwarnings('ignore')

# Configuration des graphiques
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 10

print("="*80)
print("COMPTE RENDU : D√âTECTION DE FRAUDE PAR CARTE BANCAIRE")
print("="*80)
print("\nüìÅ Chargement des donn√©es...")

# =============================================================================
# 1. CHARGEMENT ET EXPLORATION DES DONN√âES
# =============================================================================

# Charger le dataset
df = pd.read_csv('creditcard.csv')

print("\n" + "="*80)
print("1. DESCRIPTION DU DATASET")
print("="*80)

print(f"\nüìä Informations g√©n√©rales :")
print(f"  ‚Ä¢ Nombre total de transactions : {len(df):,}")
print(f"  ‚Ä¢ Nombre de variables : {df.shape[1]}")
print(f"  ‚Ä¢ P√©riode : 2 jours (septembre 2013)")
print(f"  ‚Ä¢ Dur√©e totale : {df['Time'].max():,.0f} secondes (~{df['Time'].max()/3600:.1f} heures)")

print(f"\nüìã Types de variables :")
print(f"  ‚Ä¢ Variables PCA (V1-V28) : 28 features anonymis√©es")
print(f"  ‚Ä¢ Time : Secondes √©coul√©es depuis la premi√®re transaction")
print(f"  ‚Ä¢ Amount : Montant de la transaction (‚Ç¨)")
print(f"  ‚Ä¢ Class : Variable cible (0=l√©gitime, 1=fraude)")

print(f"\nüéØ Distribution des classes :")
class_counts = df['Class'].value_counts()
print(f"  ‚Ä¢ Transactions l√©gitimes (0) : {class_counts[0]:,} ({class_counts[0]/len(df)*100:.3f}%)")
print(f"  ‚Ä¢ Transactions frauduleuses (1) : {class_counts[1]:,} ({class_counts[1]/len(df)*100:.3f}%)")
print(f"  ‚Ä¢ Ratio de d√©s√©quilibre : {class_counts[0]/class_counts[1]:.1f}:1")

print(f"\nüí∞ Statistiques des montants :")
print(f"\nToutes transactions :")
print(f"  ‚Ä¢ Moyenne : ‚Ç¨{df['Amount'].mean():.2f}")
print(f"  ‚Ä¢ M√©diane : ‚Ç¨{df['Amount'].median():.2f}")
print(f"  ‚Ä¢ √âcart-type : ‚Ç¨{df['Amount'].std():.2f}")
print(f"  ‚Ä¢ Min : ‚Ç¨{df['Amount'].min():.2f}")
print(f"  ‚Ä¢ Max : ‚Ç¨{df['Amount'].max():.2f}")

legitimate = df[df['Class'] == 0]['Amount']
fraud = df[df['Class'] == 1]['Amount']

print(f"\nTransactions l√©gitimes :")
print(f"  ‚Ä¢ Moyenne : ‚Ç¨{legitimate.mean():.2f}")
print(f"  ‚Ä¢ M√©diane : ‚Ç¨{legitimate.median():.2f}")

print(f"\nTransactions frauduleuses :")
print(f"  ‚Ä¢ Moyenne : ‚Ç¨{fraud.mean():.2f}")
print(f"  ‚Ä¢ M√©diane : ‚Ç¨{fraud.median():.2f}")

print(f"\nüîç Valeurs manquantes :")
missing = df.isnull().sum()
if missing.sum() == 0:
    print("  ‚úì Aucune valeur manquante d√©tect√©e")
else:
    print(missing[missing > 0])

# =============================================================================
# 2. VISUALISATIONS GRAPHIQUES
# =============================================================================

print("\n" + "="*80)
print("2. G√âN√âRATION DES VISUALISATIONS")
print("="*80)

# 2.1 Distribution des classes
print("\nüìä G√©n√©ration du graphique 1/8 : Distribution des classes...")
plt.figure(figsize=(10, 6))
colors = ['#2ecc71', '#e74c3c']
bars = plt.bar(['L√©gitime', 'Fraude'], class_counts.values, color=colors, 
               edgecolor='black', linewidth=2)
plt.title('Distribution des Classes de Transactions', fontsize=16, fontweight='bold')
plt.ylabel('Nombre de Transactions', fontsize=12)
plt.yscale('log')
for i, (bar, v) in enumerate(zip(bars, class_counts.values)):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{v:,}\n({v/len(df)*100:.3f}%)',
             ha='center', va='bottom', fontweight='bold', fontsize=11)
plt.tight_layout()
plt.savefig('fraud_1_class_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

# 2.2 Distribution des montants
print("üìä G√©n√©ration du graphique 2/8 : Distribution des montants...")
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

axes[0].hist(df['Amount'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)
axes[0].set_xlabel('Montant (‚Ç¨)', fontsize=12)
axes[0].set_ylabel('Fr√©quence', fontsize=12)
axes[0].set_title('Distribution des Montants - Toutes Transactions', fontsize=14, fontweight='bold')
axes[0].set_xlim([0, 1000])
axes[0].axvline(df['Amount'].mean(), color='red', linestyle='--', linewidth=2, label=f'Moyenne: ‚Ç¨{df["Amount"].mean():.2f}')
axes[0].axvline(df['Amount'].median(), color='orange', linestyle='--', linewidth=2, label=f'M√©diane: ‚Ç¨{df["Amount"].median():.2f}')
axes[0].legend()

axes[1].hist(legitimate, bins=50, alpha=0.6, label='L√©gitime', color='green', edgecolor='black')
axes[1].hist(fraud, bins=50, alpha=0.6, label='Fraude', color='red', edgecolor='black')
axes[1].set_xlabel('Montant (‚Ç¨)', fontsize=12)
axes[1].set_ylabel('Fr√©quence', fontsize=12)
axes[1].set_title('Comparaison des Montants : L√©gitime vs Fraude', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=12)
axes[1].set_xlim([0, 500])

plt.tight_layout()
plt.savefig('fraud_2_amount_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

# 2.3 Boxplot des montants par classe
print("üìä G√©n√©ration du graphique 3/8 : Boxplot des montants...")
plt.figure(figsize=(10, 6))
sns.boxplot(x='Class', y='Amount', data=df, palette=['#2ecc71', '#e74c3c'])
plt.xticks([0, 1], ['L√©gitime (0)', 'Fraude (1)'], fontsize=12)
plt.xlabel('Type de Transaction', fontsize=12, fontweight='bold')
plt.ylabel('Montant (‚Ç¨)', fontsize=12, fontweight='bold')
plt.title('Distribution des Montants par Classe de Transaction', fontsize=14, fontweight='bold')
plt.ylim([0, 300])
plt.tight_layout()
plt.savefig('fraud_3_amount_boxplot.png', dpi=300, bbox_inches='tight')
plt.show()

# 2.4 Distribution temporelle
print("üìä G√©n√©ration du graphique 4/8 : Distribution temporelle...")
fig, axes = plt.subplots(2, 1, figsize=(14, 10))

axes[0].scatter(df['Time'], df['Amount'], alpha=0.3, s=1, color='steelblue')
axes[0].set_xlabel('Temps (secondes)', fontsize=12)
axes[0].set_ylabel('Montant (‚Ç¨)', fontsize=12)
axes[0].set_title('Distribution Temporelle des Transactions', fontsize=14, fontweight='bold')
axes[0].set_ylim([0, 2000])
axes[0].grid(True, alpha=0.3)

fraud_df = df[df['Class'] == 1]
axes[1].scatter(fraud_df['Time'], fraud_df['Amount'], color='red', alpha=0.7, s=50, edgecolor='black', linewidth=0.5)
axes[1].set_xlabel('Temps (secondes)', fontsize=12)
axes[1].set_ylabel('Montant (‚Ç¨)', fontsize=12)
axes[1].set_title(f'Distribution Temporelle des Fraudes ({len(fraud_df)} transactions)', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('fraud_4_temporal_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

# 2.5 Distribution des variables PCA importantes
print("üìä G√©n√©ration du graphique 5/8 : Distribution des variables PCA...")
important_features = ['V1', 'V2', 'V3', 'V4', 'V9', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18']

fig, axes = plt.subplots(3, 4, figsize=(18, 12))
axes = axes.ravel()

for idx, feature in enumerate(important_features):
    axes[idx].hist(df[df['Class'] == 0][feature], bins=50, alpha=0.6, 
                   label='L√©gitime', color='green', density=True)
    axes[idx].hist(df[df['Class'] == 1][feature], bins=50, alpha=0.6, 
                   label='Fraude', color='red', density=True)
    axes[idx].set_title(f'Distribution de {feature}', fontweight='bold', fontsize=11)
    axes[idx].legend(fontsize=9)
    axes[idx].set_ylabel('Densit√©', fontsize=9)
    axes[idx].grid(True, alpha=0.3)

plt.suptitle('Distribution des Composantes PCA - L√©gitime vs Fraude', 
             fontsize=16, fontweight='bold', y=1.00)
plt.tight_layout()
plt.savefig('fraud_5_pca_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# 3. PR√âPARATION DES DONN√âES POUR LA MOD√âLISATION
# =============================================================================

print("\n" + "="*80)
print("3. PR√âPARATION DES DONN√âES")
print("="*80)

X = df.drop('Class', axis=1)
y = df['Class']

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\n‚úì Split des donn√©es :")
print(f"  ‚Ä¢ Train set : {len(X_train):,} samples")
print(f"  ‚Ä¢ Test set : {len(X_test):,} samples")
print(f"  ‚Ä¢ Distribution train - L√©gitime : {sum(y_train==0):,}, Fraude : {sum(y_train==1):,}")
print(f"  ‚Ä¢ Distribution test - L√©gitime : {sum(y_test==0):,}, Fraude : {sum(y_test==1):,}")

# Normalisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"\n‚úì Normalisation appliqu√©e (StandardScaler)")

# Application de SMOTE
print(f"\n‚öôÔ∏è Application de SMOTE pour √©quilibrer les classes...")
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

print(f"  ‚Ä¢ Avant SMOTE : {Counter(y_train)}")
print(f"  ‚Ä¢ Apr√®s SMOTE : {Counter(y_train_balanced)}")
print(f"  ‚Ä¢ Taille du dataset d'entra√Ænement : {len(X_train_balanced):,} samples")

# 3.1 Visualisation de l'impact du r√©√©chantillonnage
print("\nüìä G√©n√©ration du graphique 6/8 : Impact du r√©√©chantillonnage...")
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

axes[0].bar(['L√©gitime', 'Fraude'], [sum(y_train == 0), sum(y_train == 1)], 
            color=['green', 'red'], edgecolor='black', linewidth=2)
axes[0].set_title('Distribution Originale (Train)', fontsize=14, fontweight='bold')
axes[0].set_ylabel('Nombre de samples', fontsize=12)
axes[0].set_yscale('log')
for i, v in enumerate([sum(y_train == 0), sum(y_train == 1)]):
    axes[0].text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')

axes[1].bar(['L√©gitime', 'Fraude'], [sum(y_train_balanced == 0), sum(y_train_balanced == 1)], 
            color=['green', 'red'], edgecolor='black', linewidth=2)
axes[1].set_title('Apr√®s SMOTE (√âquilibr√©)', fontsize=14, fontweight='bold')
axes[1].set_ylabel('Nombre de samples', fontsize=12)
for i, v in enumerate([sum(y_train_balanced == 0), sum(y_train_balanced == 1)]):
    axes[1].text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.savefig('fraud_6_smote_impact.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# 4. ENTRA√éNEMENT DES MOD√àLES
# =============================================================================

print("\n" + "="*80)
print("4. ENTRA√éNEMENT ET √âVALUATION DES MOD√àLES")
print("="*80)

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, 
                             random_state=42, eval_metric='logloss', n_jobs=-1)
}

results = []
predictions = {}
probabilities = {}

for name, model in models.items():
    print(f"\nüîÑ Entra√Ænement : {name}...")
    
    # Entra√Ænement
    model.fit(X_train_balanced, y_train_balanced)
    
    # Pr√©dictions
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
    
    predictions[name] = y_pred
    probabilities[name] = y_pred_proba
    
    # Calcul des m√©triques
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 0
    
    results.append({
        'Mod√®le': name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'ROC-AUC': roc_auc
    })
    
    print(f"  ‚úì Accuracy  : {accuracy:.4f}")
    print(f"  ‚úì Precision : {precision:.4f}")
    print(f"  ‚úì Recall    : {recall:.4f}")
    print(f"  ‚úì F1-Score  : {f1:.4f}")
    print(f"  ‚úì ROC-AUC   : {roc_auc:.4f}")

# =============================================================================
# 5. COMPARAISON DES R√âSULTATS
# =============================================================================

results_df = pd.DataFrame(results).sort_values('F1-Score', ascending=False)

print("\n" + "="*80)
print("5. TABLEAU R√âCAPITULATIF DES PERFORMANCES")
print("="*80)
print("\n" + results_df.to_string(index=False))

best_model_name = results_df.iloc[0]['Mod√®le']
print(f"\nüèÜ Meilleur mod√®le : {best_model_name} (F1-Score: {results_df.iloc[0]['F1-Score']:.4f})")

# 5.1 Visualisation des performances
print("\nüìä G√©n√©ration du graphique 7/8 : Comparaison des performances...")
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']

for idx, metric in enumerate(metrics):
    ax = axes[idx // 2, idx % 2]
    sorted_df = results_df.sort_values(metric, ascending=True)
    bars = ax.barh(sorted_df['Mod√®le'], sorted_df[metric], color=colors[idx], 
                   edgecolor='black', linewidth=1.5)
    ax.set_xlabel(metric, fontsize=12, fontweight='bold')
    ax.set_xlim([0, 1])
    ax.set_title(f'Comparaison : {metric}', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')
    
    for i, (bar, v) in enumerate(zip(bars, sorted_df[metric])):
        ax.text(v + 0.01, bar.get_y() + bar.get_height()/2, 
                f'{v:.3f}', va='center', fontweight='bold', fontsize=10)

plt.tight_layout()
plt.savefig('fraud_7_model_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# 6. ANALYSE D√âTAILL√âE DU MEILLEUR MOD√àLE
# =============================================================================

print("\n" + "="*80)
print("6. ANALYSE D√âTAILL√âE DU MEILLEUR MOD√àLE")
print("="*80)

best_predictions = predictions[best_model_name]
best_probabilities = probabilities[best_model_name]

# Matrice de confusion
cm = confusion_matrix(y_test, best_predictions)
TN, FP, FN, TP = cm.ravel()

print(f"\nüìä Matrice de Confusion - {best_model_name} :")
print(f"  ‚Ä¢ True Negatives (TN)  : {TN:,} (vraies transactions l√©gitimes)")
print(f"  ‚Ä¢ False Positives (FP) : {FP:,} (fausses alertes de fraude)")
print(f"  ‚Ä¢ False Negatives (FN) : {FN:,} (fraudes manqu√©es) ‚ö†Ô∏è")
print(f"  ‚Ä¢ True Positives (TP)  : {TP:,} (fraudes correctement d√©tect√©es) ‚úì")

print(f"\nüí° Interpr√©tation :")
print(f"  ‚Ä¢ Taux de vraies d√©tections : {TP/(TP+FN)*100:.2f}% des fraudes d√©tect√©es")
print(f"  ‚Ä¢ Taux de fausses alertes : {FP/(TN+FP)*100:.2f}% des transactions l√©gitimes")

# Rapport de classification
print(f"\nüìã Rapport de Classification D√©taill√© :")
print("\n" + classification_report(y_test, best_predictions, 
                                   target_names=['L√©gitime', 'Fraude'],
                                   digits=4))

# 6.1 Visualisation de la matrice de confusion
print("\nüìä G√©n√©ration du graphique 8/8 : Analyses finales...")
fig = plt.figure(figsize=(18, 6))
gs = fig.add_gridspec(1, 3, hspace=0.3, wspace=0.3)

# Matrice de confusion
ax1 = fig.add_subplot(gs[0, 0])
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,
            xticklabels=['L√©gitime', 'Fraude'],
            yticklabels=['L√©gitime', 'Fraude'],
            annot_kws={'size': 14, 'weight': 'bold'}, ax=ax1)
ax1.set_title(f'Matrice de Confusion\n{best_model_name}', fontsize=12, fontweight='bold')
ax1.set_ylabel('Valeur R√©elle', fontsize=11)
ax1.set_xlabel('Valeur Pr√©dite', fontsize=11)

# Courbe ROC
ax2 = fig.add_subplot(gs[0, 1])
for name, proba in probabilities.items():
    if proba is not None:
        fpr, tpr, _ = roc_curve(y_test, proba)
        auc = roc_auc_score(y_test, proba)
        ax2.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', linewidth=2)

ax2.plot([0, 1], [0, 1], 'k--', label='Hasard (AUC=0.500)', linewidth=2)
ax2.set_xlabel('Taux de Faux Positifs', fontsize=11)
ax2.set_ylabel('Taux de Vrais Positifs', fontsize=11)
ax2.set_title('Courbes ROC', fontsize=12, fontweight='bold')
ax2.legend(loc='lower right', fontsize=8)
ax2.grid(True, alpha=0.3)

# Courbe Precision-Recall
ax3 = fig.add_subplot(gs[0, 2])
for name, proba in probabilities.items():
    if proba is not None:
        precision_vals, recall_vals, _ = precision_recall_curve(y_test, proba)
        ax3.plot(recall_vals, precision_vals, label=name, linewidth=2)

ax3.set_xlabel('Recall', fontsize=11)
ax3.set_ylabel('Precision', fontsize=11)
ax3.set_title('Courbes Precision-Recall', fontsize=12, fontweight='bold')
ax3.legend(loc='lower left', fontsize=8)
ax3.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('fraud_8_final_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# 7. CONCLUSION
# =============================================================================

print("\n" + "="*80)
print("7. CONCLUSION ET RECOMMANDATIONS")
print("="*80)

print("\n‚úÖ POINTS CL√âS :")
print("  ‚Ä¢ Dataset r√©aliste avec 284,807 transactions authentiques")
print("  ‚Ä¢ D√©s√©quilibre extr√™me : 0.173% de fraudes (1:577)")
print("  ‚Ä¢ Variables anonymis√©es via PCA pour confidentialit√©")
print(f"  ‚Ä¢ Meilleur mod√®le : {best_model_name}")
print(f"    - F1-Score : {results_df.iloc[0]['F1-Score']:.4f}")
print(f"    - ROC-AUC : {results_df.iloc[0]['ROC-AUC']:.4f}")
print(f"    - Recall : {results_df.iloc[0]['Recall']:.4f} (crucial pour d√©tecter les fraudes)")

print("\nüìå RECOMMANDATIONS :")
print("  1. Feature Engineering :")
print("     - Agr√©gations temporelles (transactions/heure)")
print("     - Statistiques par utilisateur")
print("     - Patterns de comportement")
print("\n  2. Optimisation des seuils :")
print("     - Ajuster selon le co√ªt m√©tier")
print("     - Privil√©gier le Recall (minimiser fraudes manqu√©es)")
print("\n  3. D√©ploiement :")
print("     - Scoring temps r√©el (< 100ms)")
print("     - Monitoring continu")
print("     - R√©entra√Ænement r√©gulier")
print("\n  4. Gestion des co√ªts :")
print("     - Co√ªt fraude manqu√©e > Co√ªt faux positif")
print("     - Optimiser selon matrice de co√ªts m√©tier")

print("\nüéØ APPLICATIONS PRATIQUES :")
print("  ‚Ä¢ D√©tection temps r√©el pour syst√®mes bancaires")
print("  ‚Ä¢ Scoring de risque pour √©metteurs de cartes")
print("  ‚Ä¢ Identification de patterns de fraude √©mergents")
print("  ‚Ä¢ Analyse forensique post-fraude")
print("  ‚Ä¢ R√©duction de la r√©vision manuelle")

print("\n" + "="*80)
print("‚úì ANALYSE TERMIN√âE AVEC SUCC√àS")
print("="*80)
print(f"\nüìÅ Fichiers g√©n√©r√©s :")
print("  ‚Ä¢ fraud_1_class_distribution.png")
print("  ‚Ä¢ fraud_2_amount_distribution.png")
print("  ‚Ä¢ fraud_3_amount_boxplot.png")
print("  ‚Ä¢ fraud_4_temporal_distribution.png")
print("  ‚Ä¢ fraud_5_pca_distributions.png")
print("  ‚Ä¢ fraud_6_smote_impact.png")
print("  ‚Ä¢ fraud_7_model_comparison.png")
print("  ‚Ä¢ fraud_8_final_analysis.png")

print("\nüìä Source : Kaggle - Credit Card Fraud Detection")
print("üèõÔ∏è Dataset : Machine Learning Group - ULB")
print("üìÖ Date : Novembre 2025")
print("\n" + "="*80)
